{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import os.path as op\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from fastai.vision import *\n",
    "from fastai.vision.all import *\n",
    "from typing import Union, List\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "import uvicorn\n",
    "from fastapi import File, UploadFile, FastAPI, status\n",
    "from fastapi.encoders import jsonable_encoder\n",
    "\n",
    "from fastapi.responses import JSONResponse\n",
    "\n",
    "from modules import (\n",
    "    DRModel,\n",
    "    DRClassifier,\n",
    "    ImageQualityModel,\n",
    "    FundusImageQualityClassifier,\n",
    "    YoloCupDiscSegmentor,\n",
    "    GlaucomaClassifier,\n",
    "    EyeScreener,\n",
    ")\n",
    "from modules.utils.segmentation_utils import *\n",
    "\n",
    "## allow loading large images\n",
    "from PIL import ImageFile\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "TEMPORARY_IMAGE_FOLDER = \"temp_images\"\n",
    "YOLO_CUP_DISC_SEGMENTOR_TEMP_DIR = \"temp_predicted_masks\"\n",
    "\n",
    "image_quality_model_path = \"trained_models/image_quality_resnet18_512d_512_18ep\"\n",
    "dr_model_path = \"trained_models/dr_se_resnext50_32x4d_224_15ep\"\n",
    "cup_model_path = \"trained_models/yolo-cup-15ep/weights/best.pt\"\n",
    "disc_model_path = \"trained_models/yolo-disc-15ep/weights/best.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screener = EyeScreener(\n",
    "    image_quality_model_path=image_quality_model_path,\n",
    "    dr_model_path=dr_model_path,\n",
    "    cup_model_path=cup_model_path,\n",
    "    disc_model_path=disc_model_path,\n",
    "    glaucoma_model_path=None,\n",
    "    device=DEVICE,\n",
    "    # Select the machine type (Nidek or Eidon).\n",
    "    # machine_type=\"Nidek\",\n",
    "    # Optional kwargs for the cup_disc_segmentor and their default values.\n",
    "    # measure_mask_length_from_height = True, # If False, then from width.\n",
    "    temp_save_dir=YOLO_CUP_DISC_SEGMENTOR_TEMP_DIR,  # Change the name of the temp dir.\n",
    "    clear_temp_dir_after=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    # Save the image to a temporary folder so that the screener can load it.\n",
    "    temp_image_name = \"temp_image.png\"\n",
    "    temp_image_path = op.join(TEMPORARY_IMAGE_FOLDER, temp_image_name)\n",
    "    os.makedirs(TEMPORARY_IMAGE_FOLDER, exist_ok=True)\n",
    "    image.save(temp_image_path)\n",
    "\n",
    "    # Predict the image.\n",
    "    predicted_dict = screener.predict(image_path=temp_image_path)\n",
    "    # Parse the output.\n",
    "    image_quality_output = {\n",
    "        \"Image Quality: Good\": predicted_dict[\"image_quality\"][\"probability\"][\"good\"],\n",
    "        \"Image Quality: Acceptable\": predicted_dict[\"image_quality\"][\"probability\"][\"acceptable\"],\n",
    "        \"Image Quality: Poor\": predicted_dict[\"image_quality\"][\"probability\"][\"poor\"],\n",
    "    }\n",
    "\n",
    "    return [image_quality_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"pred_img_quality_all_label_3000.csv\")\n",
    "# df = df[[\"filename\", \"original_path\", \"image_quality\"]]\n",
    "# df[\"original_path\"] = df[\"original_path\"].apply(lambda x: os.path.basename(x))\n",
    "# df.dropna(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pred_image_quality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "xml_file = \"../annotations.xml\"\n",
    "tree = etree.parse(xml_file)\n",
    "images = tree.findall(\".//image\")\n",
    "\n",
    "image_quality = []\n",
    "\n",
    "for image in tqdm(images):\n",
    "  image_name = image.get(\"name\")\n",
    "  tag = image.findall(\"tag\")\n",
    "\n",
    "  if tag is not None:\n",
    "    for tg in tag:\n",
    "      text = tg.get(\"label\")\n",
    "\n",
    "      if text == \"GLAUCOMA SUSPECT\":\n",
    "        continue\n",
    "  \n",
    "      image_quality.append({\"file_name\": image_name,\n",
    "                            \"image_quality\": text})\n",
    "      \n",
    "\n",
    "pd.DataFrame(image_quality).to_csv(\"image_quality_label.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df[df[\"pred_image_quality\"].isna()]\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "\n",
    "imgs = glob(\"../siriraj-eye-dataset-2023-jan/siriraj-eye-dataset-2023-jan/images/default/*.jpg\")\n",
    "original_paths = list(df_pred[\"file_name\"])\n",
    "print(len(imgs), len(original_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "count = 0\n",
    "\n",
    "for img in imgs:\n",
    "    img_name = os.path.basename(img)\n",
    "    if img_name in original_paths:\n",
    "        count += 1\n",
    "        # print(img_name)\n",
    "\n",
    "print(\"Count: \", count, \" / \", len(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "num = 1000\n",
    "\n",
    "for img in tqdm(imgs):\n",
    "    img_name = os.path.basename(img)\n",
    "\n",
    "    if img_name in original_paths:\n",
    "        results = predict(Image.open(img))\n",
    "        quality = results[0]\n",
    "        highest_quality = max(quality, key=quality.get)\n",
    "        quality_type = highest_quality.split(': ')[1].upper()\n",
    "\n",
    "        df.loc[df[\"file_name\"] == img_name, \"pred_image_quality\"] = quality_type\n",
    "        num += 1\n",
    "        print(f\"Working on .. images num {num}  .. :\", img_name , end='\\r')\n",
    "\n",
    "    if num % 1000 == 0:\n",
    "        df.to_csv(f\"pred_img_quality_all_label_{num}.csv\", index=False)\n",
    "\n",
    "df = df.dropna()\n",
    "df.to_csv(f\"pred_img_quality_all_label_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[df[\"image_quality\"] != df[\"pred_image_quality\"]]\n",
    "\n",
    "new_df.to_csv(\"mismatched_img_quality.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>image_quality</th>\n",
       "      <th>pred_image_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>603L (C).jpg</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>ACCEPTABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160L (C).jpg</td>\n",
       "      <td>POOR</td>\n",
       "      <td>ACCEPTABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116R (2).jpg</td>\n",
       "      <td>ACCEPTABLE</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116L (2).jpg</td>\n",
       "      <td>ACCEPTABLE</td>\n",
       "      <td>POOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106R (2).jpg</td>\n",
       "      <td>ACCEPTABLE</td>\n",
       "      <td>POOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>9e7b7717ab1aa7922eac8c27a860e500.jpg</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>ACCEPTABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>81300bb243f0558499b7019fd5357db0.jpg</td>\n",
       "      <td>ACCEPTABLE</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>5efbecd76168a7859798532171747659.jpg</td>\n",
       "      <td>ACCEPTABLE</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>5a5734d4024726606495d5f218a30011.jpg</td>\n",
       "      <td>POOR</td>\n",
       "      <td>ACCEPTABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>2f82632b636092932e09209e1f615373.jpg</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>ACCEPTABLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>274 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                file_name image_quality pred_image_quality\n",
       "0                            603L (C).jpg          GOOD         ACCEPTABLE\n",
       "1                            160L (C).jpg          POOR         ACCEPTABLE\n",
       "2                            116R (2).jpg    ACCEPTABLE               GOOD\n",
       "3                            116L (2).jpg    ACCEPTABLE               POOR\n",
       "4                            106R (2).jpg    ACCEPTABLE               POOR\n",
       "..                                    ...           ...                ...\n",
       "269  9e7b7717ab1aa7922eac8c27a860e500.jpg          GOOD         ACCEPTABLE\n",
       "270  81300bb243f0558499b7019fd5357db0.jpg    ACCEPTABLE               GOOD\n",
       "271  5efbecd76168a7859798532171747659.jpg    ACCEPTABLE               GOOD\n",
       "272  5a5734d4024726606495d5f218a30011.jpg          POOR         ACCEPTABLE\n",
       "273  2f82632b636092932e09209e1f615373.jpg          GOOD         ACCEPTABLE\n",
       "\n",
       "[274 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(\"dif_quality_pred_images\", exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(\"mismatched_img_quality.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = glob(\"../siriraj-eye-dataset-2023-jan/siriraj-eye-dataset-2023-jan/images/default/*.jpg\")\n",
    "\n",
    "for img in imgs:\n",
    "    if os.path.basename(img) in list(df[\"file_name\"]):\n",
    "        shutil.copy(img, \"dif_quality_pred_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274\n"
     ]
    }
   ],
   "source": [
    "dif_imgs = glob(\"dif_quality_pred_images/*.jpg\")\n",
    "print(len(dif_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = [df[\"image_quality\"] == df[\"pred_image_quality\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
